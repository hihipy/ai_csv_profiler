# aiâ€‘csvâ€‘profiler

*A Python utility that builds concise, AIâ€‘friendly JSON profiles of CSV files.
Both a modern Tkinter GUI and a pureâ€‘commandâ€‘line interface are provided, so you can explore data interactively or automate profiling in scripts.*

------

## ğŸ¯ What the tool does

| Feature                          | Why it matters                                               |
| -------------------------------- | ------------------------------------------------------------ |
| **AIâ€‘Optimized JSON output**     | Gives downstream assistants (ChatGPT, Claude, etc.) exactly the fields they needâ€”no fluff. |
| **Dual UI** â€“ GUIâ€¯+â€¯CLI          | Pick the workflow that fits your habit: dragâ€‘andâ€‘drop or batchâ€‘process. |
| **Smart type detection**         | Autoâ€‘recognises numeric, text, date/time, boolean and categorical columns. |
| **Rich numeric analysis**        | Means, medians, quartiles, IQRâ€‘based outlier count, skewness, autoâ€‘ID/currency detection. |
| **Robust file handling**         | Tries several encodings, warns on huge files, validates format before parsing. |
| **Threadâ€‘safe GUI**              | The UI stays responsive while the profiler works in the background. |
| **Comprehensive error handling** | Friendly messages for missing files, permission problems, malformed CSVs, etc. |

------

## ğŸ“¦ Requirements

*Pythonâ€¯3.6+*

```
pip install pandas
```

### Linux â€“ installing Tkinter

```
# Debian/Ubuntu
sudo apt-get install python3-tk

# Fedora/CentOS/RHEL
sudo dnf install python3-tkinter   # or: sudo yum install tkinter
```

> **Note:** `tkinter`, `threading`, `queue`, `argparse`, `json`, `os`, `pathlib` are part of the Python standard library and need no extra installation.

------

## ğŸš€ Installation

```
# Grab the latest script
curl -O https://raw.githubusercontent.com/your-repo/ai-csv-profiler/main/ai_csv_profiler.py

# (Optional) Make it directly executable
chmod +x ai_csv_profiler.py
```

------

## ğŸ–¥ï¸ Usage

### GUI mode (default)

```
python ai_csv_profiler.py
```

1. **Select file** â€“ â€œBrowseâ€¦â€ â†’ pick a CSV.
2. **Choose output** â€“ â€œSave Asâ€¦â€ â†’ set the destination JSON file.
3. **Configure** â€“ tick/untick *Include sample values* and *Detailed statistical analysis*.
4. **Analyze** â€“ press **ğŸ” Analyze CSV**.
5. **Results** â€“ a JSON file is written and a short summary appears in the log pane.

### CLI mode

```
# Minimal â€“ prints JSON to stdout
python ai_csv_profiler.py data.csv

# Write to a specific file
python ai_csv_profiler.py data.csv -o profile.json

# Longâ€‘form flags (identical effect)
python ai_csv_profiler.py data.csv --output analysis_results.json
```

Additional flags (shown in `--help`):

| Flag               | Description                                                |
| ------------------ | ---------------------------------------------------------- |
| `--no-samples`     | Omit the three example values per column (smaller output). |
| `--simple`         | Skip heavy statistics (faster, less detail).               |
| `-v` / `--verbose` | Show progress messages and any warnings on the console.    |

------

## ğŸ“Š Output format

The profiler writes a single JSON document. Below is a trimmed example that illustrates the schema:

```
{
  "file": "sample.csv",
  "shape": { "rows": 1000, "columns": 5 },
  "columns": [
    {
      "name": "customer_id",
      "type": "numeric",
      "non_null": 1000,
      "nulls": 0,
      "samples": ["1", "2", "3"],
      "analysis": "numeric",
      "min": 1,
      "max": 1000,
      "mean": 500.5,
      "median": 500,
      "std": 288.7,
      "zeroes": 0,
      "positives": 1000,
      "negatives": 0,
      "distinct": 1000,
      "likely_id": true
    },
    {
      "name": "revenue",
      "type": "numeric",
      "non_null": 995,
      "nulls": 5,
      "samples": ["1250.50", "890.25", "2100.00"],
      "analysis": "numeric",
      "min": 45.0,
      "max": 9876.0,
      "mean": 1425.75,
      "median": 1200.0,
      "std": 850.3,
      "outlier_count": 23,
      "distribution": "right_skewed",
      "likely_currency": true
    },
    {
      "name": "signup_date",
      "type": "datetime",
      "non_null": 980,
      "nulls": 20,
      "samples": ["2023-01-15", "2023-02-03", "2023-03-22"],
      "analysis": "datetime",
      "min": "2022-01-01",
      "max": "2024-12-31",
      "distinct": 970
    },
    {
      "name": "country",
      "type": "categorical",
      "non_null": 1000,
      "nulls": 0,
      "samples": ["US", "DE", "FR"],
      "analysis": "categorical",
      "distinct": 12,
      "top_five": {"US": 400, "DE": 180, "FR": 150, "GB": 120, "CA": 50},
      "mode": "US"
    },
    {
      "name": "notes",
      "type": "text",
      "non_null": 950,
      "nulls": 50,
      "samples": ["VIP client", "Followâ€‘up needed", "No response"],
      "analysis": "text",
      "avg_length": 34.2,
      "max_length": 128,
      "min_length": 0,
      "contains_numbers": 120,
      "contains_special_chars": 45
    }
  ],
  "warnings": [],
  "metadata": {
    "size_bytes": 842361,
    "size_mb": 0.8,
    "memory_usage_mb": 2.3,
    "column_types": {
      "customer_id": "object",
      "revenue": "object",
      "signup_date": "object",
      "country": "object",
      "notes": "object"
    }
  }
}
```

### Key fields per column

| Field                | Meaning                                                      |
| -------------------- | ------------------------------------------------------------ |
| `type`               | Detected highâ€‘level type (`numeric`, `datetime`, `categorical`, `text`). |
| `non_null` / `nulls` | Count of present vs. missing values.                         |
| `samples`            | Three representative nonâ€‘null values (truncated to 100â€¯chars). |
| `analysis`           | Subâ€‘section name â€“ tells you which block of stats follows.   |
| Numericâ€‘specific     | `min`, `max`, `mean`, `median`, `std`, `outlier_count`, `distribution`, `likely_id`, `likely_currency`. |
| Datetimeâ€‘specific    | `min`, `max`, `distinct`, `nulls_after_parse`.               |
| Categoricalâ€‘specific | `distinct`, `top_five` (value â†’ count), `mode`.              |
| Textâ€‘specific        | Length stats, presence of numbers/special characters.        |

------

## ğŸ› ï¸ Technical notes

| Aspect                  | Detail                                                       |
| ----------------------- | ------------------------------------------------------------ |
| **Framework**           | Tkinter (crossâ€‘platform GUI).                                |
| **Data engine**         | pandas for CSV parsing and statistical calculations.         |
| **Threading**           | GUI launches a background `threading.Thread`; results are passed back via a `queue.Queue`. |
| **Encoding fallback**   | Tries UTFâ€‘8 â†’ UTFâ€‘8â€‘sig â†’ CP1252 â†’ ISOâ€‘8859â€‘1 â†’ latin1 â†’ ASCII â†’ UTFâ€‘16 â†’ UTFâ€‘32. |
| **Largeâ€‘file handling** | Files >â€¯500â€¯MiB are read in chunks; a warning is added to the JSON `warnings` array. |
| **Memory usage**        | `df.memory_usage(deep=True)` is reported; the profiler never forces the whole file into RAM when it can be chunked. |
| **Error resilience**    | Every public method catches exceptions and returns a sensible default, ensuring the program never crashes. |

------

## â— Error handling

| Situation                   | Message shown to the user                                    |
| --------------------------- | ------------------------------------------------------------ |
| File not found / unreadable | â€œError: `<path>` not found or cannot be opened.â€             |
| Empty file                  | â€œFile is empty â€“ nothing to profile.â€                        |
| Unsupported encoding        | â€œAll encoding attempts failed â€“ please verify the fileâ€™s character set.â€ |
| Very large file (>â€¯100â€¯MB)  | â€œLarge file detected (â‰ˆâ€¯Xâ€¯MB). Continue? (Y/N)â€ (CLI) / GUI shows a modal warning. |
| Unexpected parsing error    | â€œCritical analysis failure: `<exception>` â€“ see log for stack trace.â€ |

All messages are logged to the GUIâ€™s text pane and printed to `stderr` in CLI mode.

------

## ğŸ’¡ Typical use cases

- **Quick data discovery** â€“ Open an unknown CSV and get a concise summary within seconds.
- **AIâ€‘assistant pipelines** â€“ Feed the JSON profile to LLMs that need structural hints before prompting.
- **Dataâ€‘quality audits** â€“ Spot missing values, outliers, and inconsistent types early.
- **Preâ€‘processing planning** â€“ Decide which columns need cleaning, encoding, or transformation before feeding data to a model.
- **Documentation generation** â€“ Export the JSON as part of a datasetâ€™s metadata bundle.

------

## ğŸ“œ License

`ai-csv-profiler Â© 2025` â€“ Distributed under the [**Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International**](https://creativecommons.org/licenses/by-nc-nd/4.0/) license.

------

## ğŸ™ Acknowledgments

- **pandas** â€“ for the powerful dataâ€‘frame abstraction.
- **Tkinter** â€“ for providing a lightweight, crossâ€‘platform GUI without external dependencies.
- The openâ€‘source community for inspiration on robust CSV handling.

------

**Tip:** If you ever need the very latest bugâ€‘fixes or want to contribute, fork the repository, push your changes, and open a Pull Request. The code is deliberately modular, so adding new column analyses (e.g., sentiment scoring for text) is straightforward.